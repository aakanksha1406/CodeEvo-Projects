{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install newspaper3k feedparser\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjbKFGXTcOry",
        "outputId": "8a9345d6-1018-4b79-baa2-933fd093d70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.12.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.2)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.4)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.32.3)\n",
            "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sgmllib3k (from feedparser)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2024.8.30)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.16.0)\n",
            "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=ea76d5697b1ad7e09c8969246dbb2cbc6d5d17e3e4d0591e6fbf6b729bd2b2ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3342 sha256=dead381c1126af1ba9fd9b3a554add7ddd10c32d0f9a7039a379efa37e8eb9a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=bbbfe84b79d886a325059921c268b7d782100602e867edacad3e251ae753e24b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=2bb121e63832f8ec5067e6666e69db98bdb3956c87f24bc7035238f758905363\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-2.1.0 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "from newspaper import Article\n",
        "import pandas as pd\n",
        "\n",
        "# Function to parse RSS feeds and extract article URLs\n",
        "def parse_rss_feed(rss_url):\n",
        "    feed = feedparser.parse(rss_url)\n",
        "    article_urls = [entry['link'] for entry in feed['entries']]\n",
        "    return article_urls\n",
        "\n",
        "# Function to download and parse articles using newspaper3k\n",
        "def extract_article_info(article_url):\n",
        "    article = Article(article_url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "\n",
        "    # Extract relevant information\n",
        "    title = article.title\n",
        "    authors = ', '.join(article.authors)\n",
        "    publish_date = article.publish_date\n",
        "    content = article.text\n",
        "\n",
        "    return {\n",
        "        'URL': article_url,\n",
        "        'Title': title,\n",
        "        'Authors': authors,\n",
        "        'Publish Date': publish_date,\n",
        "        'Content': content\n",
        "    }\n",
        "\n",
        "# Function to parse RSS feeds and extract information from articles\n",
        "def extract_articles_from_rss(rss_urls):\n",
        "    articles_data = []\n",
        "\n",
        "    for rss_url in rss_urls:\n",
        "        print(f\"Processing RSS feed: {rss_url}\")\n",
        "        # Step 1: Parse RSS feed and get article URLs\n",
        "        article_urls = parse_rss_feed(rss_url)\n",
        "\n",
        "        # Step 2: For each URL, extract article info\n",
        "        for url in article_urls:\n",
        "            try:\n",
        "                print(f\"Extracting article from: {url}\")\n",
        "                article_info = extract_article_info(url)\n",
        "                articles_data.append(article_info)\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process {url}: {e}\")\n",
        "\n",
        "    return articles_data\n",
        "\n",
        "# List of RSS feeds to parse\n",
        "rss_feed_urls = [\n",
        "    \"https://rss.cnn.com/rss/cnn_topstories.rss\",\n",
        "    \"https://feeds.bbci.co.uk/news/rss.xml\",\n",
        "    \"https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml\"\n",
        "]\n",
        "\n",
        "# Step 3: Extract articles from the given RSS feeds\n",
        "articles = extract_articles_from_rss(rss_feed_urls)\n",
        "\n",
        "# Step 4: Convert the extracted data into a DataFrame and save it as a CSV file\n",
        "df = pd.DataFrame(articles)\n",
        "df.to_csv('extracted_news_articles.csv', index=False)\n",
        "\n",
        "# Display the extracted data\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZE0h9X4cNre",
        "outputId": "5d36ca89-32fc-4f0e-cdea-9c4eee4cd9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing RSS feed: https://rss.cnn.com/rss/cnn_topstories.rss\n",
            "Processing RSS feed: https://feeds.bbci.co.uk/news/rss.xml\n",
            "Extracting article from: https://www.bbc.com/news/articles/cq5eewvy3nlo\n",
            "Extracting article from: https://www.bbc.com/news/articles/c2kddp5x5zno\n",
            "Extracting article from: https://www.bbc.com/news/articles/c98486dzxnzo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cvg3g8wpwwqo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cqlvv2xwd9po\n",
            "Extracting article from: https://www.bbc.com/news/articles/c4g003lnkm9o\n",
            "Extracting article from: https://www.bbc.com/sport/football/articles/c1d7drg10nwo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cy0gg9k76w9o\n",
            "Extracting article from: https://www.bbc.com/news/articles/c5y00x52d2vo\n",
            "Extracting article from: https://www.bbc.com/news/articles/c5y3y79llndo\n",
            "Extracting article from: https://www.bbc.com/news/videos/cevyy2k1z88o\n",
            "Extracting article from: https://www.bbc.com/news/articles/cq6449gy87jo\n",
            "Extracting article from: https://www.bbc.com/news/videos/czd11ryq9rjo\n",
            "Extracting article from: https://www.bbc.com/news/articles/c1l44j5jzzyo\n",
            "Extracting article from: https://www.bbc.com/news/articles/c9qgq919yl5o\n",
            "Extracting article from: https://www.bbc.com/news/articles/c93yy4dz36no\n",
            "Extracting article from: https://www.bbc.com/news/articles/cp3dv0ddwp7o\n",
            "Extracting article from: https://www.bbc.com/news/articles/cwyw8xgeyq3o\n",
            "Extracting article from: https://www.bbc.com/news/articles/czx63pn0yp0o\n",
            "Extracting article from: https://www.bbc.com/news/articles/cn8yyy0r7epo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cnvdy6ze761o\n",
            "Extracting article from: https://www.bbc.com/news/articles/c0jwp3ppp6xo\n",
            "Extracting article from: https://www.bbc.com/news/articles/c4g99z447ylo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cp8n6g22nd5o\n",
            "Extracting article from: https://www.bbc.com/news/articles/c4g559jvp77o\n",
            "Extracting article from: https://www.bbc.com/news/articles/cy767y0y6dzo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cn5zz4rx99yo\n",
            "Extracting article from: https://www.bbc.co.uk/news/10628994\n",
            "Extracting article from: https://www.bbc.co.uk/sounds/play/p0jqsl19\n",
            "Extracting article from: https://www.bbc.co.uk/sounds/play/p0jqpp1t\n",
            "Extracting article from: https://www.bbc.co.uk/iplayer/episode/m001qhds/captain-phillips?at_mid=iI7ajKBKBD&at_campaign=Captain_Phillips&at_medium=display_ad&at_campaign_type=owned&at_audience_id=SS&at_product=iplayer&at_brand=m001qhds&at_ptr_name=bbc&at_ptr_type=media&at_format=image&at_objective=consumption&at_link_title=Captain_Phillips&at_bbc_team=BBC\n",
            "Extracting article from: https://www.bbc.com/sport/american-football/articles/c89llg00z4no\n",
            "Extracting article from: https://www.bbc.com/sport/football/articles/cx2ll0w3r2zo\n",
            "Extracting article from: https://www.bbc.com/sport/videos/c9811pg7z7eo\n",
            "Extracting article from: https://www.bbc.com/sport/football/articles/ckg2r51z2r5o\n",
            "Extracting article from: https://www.bbc.com/sport/cricket/articles/cm2nlynl95mo\n",
            "Extracting article from: https://www.bbc.com/sport/golf/articles/cyvyyqyzmglo\n",
            "Extracting article from: https://www.bbc.com/news/articles/cp8n6g22nd5o\n",
            "Extracting article from: https://www.bbc.com/news/articles/c17llzprvp5o\n",
            "Extracting article from: https://www.bbc.com/news/articles/cn5zz4rx99yo\n",
            "Processing RSS feed: https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml\n",
            "Extracting article from: https://www.nytimes.com/2024/09/15/us/politics/trump-shooting-suspect-routh.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/15/us/politics/trump-routh-ukraine-interview.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/podcasts/trump-assassination-tiktok-ban.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/world/asia/china-linda-sun-interference.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/business/energy-environment/pennsylvania-fracking-natural-gas-trump-harris.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/arts/television/emmys-best-worst-moments.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/15/arts/television/emmy-awards-winners.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/15/style/emmys-fashion.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/world/middleeast/religious-holidays-israel-gaza-war.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/world/middleeast/israel-hezbollah-lebanon-gaza.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/us/tito-jackson-dead.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/business/economy/fed-interest-rates-labor.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/nyregion/eric-adams-scandal.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/us/uvalde-shooting-arredondo-court.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/15/us/justice-roberts-trump-supreme-court.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/13/magazine/tony-tulathimutte-rejection.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/books/review/tony-tulathimutte-rejection.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/opinion/trump-harris-attempted-assassination-debate.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/opinion/inflammation-theory-of-disease.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/opinion/china-solar-climate.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/opinion/16el-ad.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/us/titan-submersible-coast-guard-hearings.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/books/review/david-brock-stench-clarence-thomas-anita-hill-media-matters.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/nyregion/street-wars-vendors.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/16/technology/tiktok-us-ban-court.html\n",
            "Extracting article from: https://www.nytimes.com/2024/09/14/style/hannah-berner-giggly-squad-netflix-we-ride-at-dawn.html\n",
            "                                              URL  \\\n",
            "0  https://www.bbc.com/news/articles/cq5eewvy3nlo   \n",
            "1  https://www.bbc.com/news/articles/c2kddp5x5zno   \n",
            "2  https://www.bbc.com/news/articles/c98486dzxnzo   \n",
            "3  https://www.bbc.com/news/articles/cvg3g8wpwwqo   \n",
            "4  https://www.bbc.com/news/articles/cqlvv2xwd9po   \n",
            "\n",
            "                                               Title Authors Publish Date  \\\n",
            "0  What we know about the Trump attack and the su...                  NaT   \n",
            "1  Tito Jackson: Jackson 5 singer, brother of Mic...                  NaT   \n",
            "2             HS2 blew billions - here's how and why                  NaT   \n",
            "3  Student loans: 'I borrowed £44,000 for univers...                  NaT   \n",
            "4  John Oliver thanks his dog and Candice Bergen ...                  NaT   \n",
            "\n",
            "                                             Content  \n",
            "0  What we know about the Trump attack and the su...  \n",
            "1  Jackson 5 singer Tito Jackson dead at 70\\n\\nGe...  \n",
            "2  HS2 blew billions - here's how and why\\n\\nBBC\\...  \n",
            "3  'I got a £44,000 student loan - now I owe £54,...  \n",
            "4  Reunions, politics and dogs: Eight Emmys highl...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXeOMcpVcd7j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}